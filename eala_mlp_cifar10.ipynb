{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0309 05:48:39.685501 139915109758784 deprecation.py:506] From /home/deepboy/.virtualenvs/keras_tf/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "/home/deepboy/.virtualenvs/keras_tf/lib/python3.6/site-packages/ipykernel_launcher.py:59: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2048)              2099200   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                20490     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 9,462,794\n",
      "Trainable params: 9,462,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 1.9813 - acc: 0.2785 - val_loss: 1.7904 - val_acc: 0.3488\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.8457 - acc: 0.3238 - val_loss: 1.7510 - val_acc: 0.3723\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.8022 - acc: 0.3415 - val_loss: 1.6851 - val_acc: 0.3981\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.7597 - acc: 0.3595 - val_loss: 1.7096 - val_acc: 0.4078\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.7420 - acc: 0.3659 - val_loss: 1.6689 - val_acc: 0.4039\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.7247 - acc: 0.3748 - val_loss: 1.6280 - val_acc: 0.4107\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.6978 - acc: 0.3848 - val_loss: 1.6072 - val_acc: 0.4267\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.6895 - acc: 0.3866 - val_loss: 1.6104 - val_acc: 0.4302\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.6823 - acc: 0.3877 - val_loss: 1.6041 - val_acc: 0.4246\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.6639 - acc: 0.3985 - val_loss: 1.6036 - val_acc: 0.4272\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.6622 - acc: 0.3997 - val_loss: 1.6102 - val_acc: 0.4388\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.6556 - acc: 0.4006 - val_loss: 1.5779 - val_acc: 0.4409\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.6388 - acc: 0.4094 - val_loss: 1.6002 - val_acc: 0.4304\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.6303 - acc: 0.4100 - val_loss: 1.5694 - val_acc: 0.4431\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.6302 - acc: 0.4137 - val_loss: 1.5600 - val_acc: 0.4482\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.6261 - acc: 0.4133 - val_loss: 1.6288 - val_acc: 0.4165\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.6277 - acc: 0.4122 - val_loss: 1.5382 - val_acc: 0.4574\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.6082 - acc: 0.4208 - val_loss: 1.5374 - val_acc: 0.4594\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.6013 - acc: 0.4193 - val_loss: 1.5463 - val_acc: 0.4541\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.5966 - acc: 0.4255 - val_loss: 1.5317 - val_acc: 0.4577\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.6000 - acc: 0.4245 - val_loss: 1.5719 - val_acc: 0.4470\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.5952 - acc: 0.4231 - val_loss: 1.6269 - val_acc: 0.4199\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.5799 - acc: 0.4315 - val_loss: 1.5079 - val_acc: 0.4642\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.5777 - acc: 0.4301 - val_loss: 1.5441 - val_acc: 0.4564\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.5694 - acc: 0.4336 - val_loss: 1.5426 - val_acc: 0.4493\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.5716 - acc: 0.4321 - val_loss: 1.5285 - val_acc: 0.4548\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5666 - acc: 0.4347 - val_loss: 1.5434 - val_acc: 0.4530\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.5636 - acc: 0.4351 - val_loss: 1.5542 - val_acc: 0.4492\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.5586 - acc: 0.4385 - val_loss: 1.5360 - val_acc: 0.4465\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.5664 - acc: 0.4346 - val_loss: 1.5028 - val_acc: 0.4620\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.5556 - acc: 0.4408 - val_loss: 1.5273 - val_acc: 0.4555\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.5476 - acc: 0.4430 - val_loss: 1.4974 - val_acc: 0.4685\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.5513 - acc: 0.4406 - val_loss: 1.5485 - val_acc: 0.4478\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.5456 - acc: 0.4431 - val_loss: 1.5351 - val_acc: 0.4516\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.5431 - acc: 0.4410 - val_loss: 1.5168 - val_acc: 0.4568\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.5390 - acc: 0.4456 - val_loss: 1.4927 - val_acc: 0.4720\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.5349 - acc: 0.4461 - val_loss: 1.5121 - val_acc: 0.4622\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5345 - acc: 0.4467 - val_loss: 1.5231 - val_acc: 0.4587\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5312 - acc: 0.4492 - val_loss: 1.5143 - val_acc: 0.4599\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.5280 - acc: 0.4523 - val_loss: 1.5772 - val_acc: 0.4333\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.5333 - acc: 0.4478 - val_loss: 1.4989 - val_acc: 0.4714\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.5217 - acc: 0.4529 - val_loss: 1.5398 - val_acc: 0.4531\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.5173 - acc: 0.4537 - val_loss: 1.4882 - val_acc: 0.4694\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.5165 - acc: 0.4555 - val_loss: 1.5008 - val_acc: 0.4673\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.5238 - acc: 0.4502 - val_loss: 1.5103 - val_acc: 0.4616\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.5164 - acc: 0.4540 - val_loss: 1.5265 - val_acc: 0.4538\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.5123 - acc: 0.4540 - val_loss: 1.5157 - val_acc: 0.4618\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.5065 - acc: 0.4584 - val_loss: 1.4968 - val_acc: 0.4681\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.5116 - acc: 0.4545 - val_loss: 1.4978 - val_acc: 0.4657\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.5092 - acc: 0.4583 - val_loss: 1.4997 - val_acc: 0.4681\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.5046 - acc: 0.4589 - val_loss: 1.4969 - val_acc: 0.4690\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.5055 - acc: 0.4570 - val_loss: 1.5141 - val_acc: 0.4594\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.5036 - acc: 0.4591 - val_loss: 1.5168 - val_acc: 0.4581\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.5013 - acc: 0.4605 - val_loss: 1.5048 - val_acc: 0.4637\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.4956 - acc: 0.4611 - val_loss: 1.4750 - val_acc: 0.4756\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.4955 - acc: 0.4596 - val_loss: 1.4859 - val_acc: 0.4704\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.4929 - acc: 0.4625 - val_loss: 1.4728 - val_acc: 0.4777\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.4933 - acc: 0.4624 - val_loss: 1.4766 - val_acc: 0.4716\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.4862 - acc: 0.4650 - val_loss: 1.5337 - val_acc: 0.4579\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.4936 - acc: 0.4604 - val_loss: 1.4724 - val_acc: 0.4752\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.4832 - acc: 0.4654 - val_loss: 1.4965 - val_acc: 0.4662\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.4843 - acc: 0.4680 - val_loss: 1.4977 - val_acc: 0.4707\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.4768 - acc: 0.4665 - val_loss: 1.5055 - val_acc: 0.4684\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.4740 - acc: 0.4679 - val_loss: 1.4812 - val_acc: 0.4704\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.4746 - acc: 0.4696 - val_loss: 1.4945 - val_acc: 0.4723\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4751 - acc: 0.4677 - val_loss: 1.4723 - val_acc: 0.4788\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.4786 - acc: 0.4668 - val_loss: 1.5086 - val_acc: 0.4550\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.4794 - acc: 0.4654 - val_loss: 1.4946 - val_acc: 0.4711\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.4759 - acc: 0.4682 - val_loss: 1.5019 - val_acc: 0.4711\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.4725 - acc: 0.4701 - val_loss: 1.4747 - val_acc: 0.4747\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.4754 - acc: 0.4667 - val_loss: 1.5164 - val_acc: 0.4574\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.4807 - acc: 0.4692 - val_loss: 1.4961 - val_acc: 0.4701\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.4687 - acc: 0.4711 - val_loss: 1.4966 - val_acc: 0.4654\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.4673 - acc: 0.4727 - val_loss: 1.4683 - val_acc: 0.4810\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.4641 - acc: 0.4728 - val_loss: 1.5205 - val_acc: 0.4620\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4702 - acc: 0.4724 - val_loss: 1.4919 - val_acc: 0.4650\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4677 - acc: 0.4727 - val_loss: 1.5119 - val_acc: 0.4578\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.4665 - acc: 0.4712 - val_loss: 1.5043 - val_acc: 0.4679\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.4645 - acc: 0.4747 - val_loss: 1.4728 - val_acc: 0.4769\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4602 - acc: 0.4743 - val_loss: 1.5079 - val_acc: 0.4666\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4752 - acc: 0.4656 - val_loss: 1.4800 - val_acc: 0.4721\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4589 - acc: 0.4738 - val_loss: 1.5034 - val_acc: 0.4664\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.4602 - acc: 0.4746 - val_loss: 1.4828 - val_acc: 0.4689\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.4626 - acc: 0.4727 - val_loss: 1.4884 - val_acc: 0.4669\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4627 - acc: 0.4739 - val_loss: 1.4821 - val_acc: 0.4752\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4567 - acc: 0.4757 - val_loss: 1.5127 - val_acc: 0.4632\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.4493 - acc: 0.4784 - val_loss: 1.4680 - val_acc: 0.4735\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.4567 - acc: 0.4774 - val_loss: 1.4874 - val_acc: 0.4753\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4409 - acc: 0.4825 - val_loss: 1.4809 - val_acc: 0.4785\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.4553 - acc: 0.4742 - val_loss: 1.4960 - val_acc: 0.4663\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.4492 - acc: 0.4784 - val_loss: 1.4786 - val_acc: 0.4741\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.4427 - acc: 0.4816 - val_loss: 1.5105 - val_acc: 0.4626\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.4399 - acc: 0.4820 - val_loss: 1.4624 - val_acc: 0.4837\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.4466 - acc: 0.4791 - val_loss: 1.4694 - val_acc: 0.4785\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.4383 - acc: 0.4846 - val_loss: 1.4634 - val_acc: 0.4818\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.4393 - acc: 0.4815 - val_loss: 1.4721 - val_acc: 0.4840\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.4411 - acc: 0.4816 - val_loss: 1.4999 - val_acc: 0.4693\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.4422 - acc: 0.4803 - val_loss: 1.4642 - val_acc: 0.4874\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.4384 - acc: 0.4841 - val_loss: 1.4879 - val_acc: 0.4741\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.4401 - acc: 0.4805 - val_loss: 1.5059 - val_acc: 0.4734\n",
      "Test loss: 1.5059048023223878\n",
      "Test acc: 0.4734\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "# Define Variables\n",
    "nb_epoch = 100\n",
    "batch_size = 32\n",
    "nb_classes = 10\n",
    "\n",
    "\n",
    "# Train - Test splitting of data\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
    "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "# Define variables and hyperparameters\n",
    "batch_size = 128\n",
    "hidden_units = 1024\n",
    "input_shape = (3072, )\n",
    "dropout = 0.2\n",
    "num_labels=10\n",
    "\n",
    "\n",
    "# Define MLP Layers\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_units, input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(hidden_units*2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(hidden_units*2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Training\n",
    "model.fit(X_train, Y_train,\n",
    "            batch_size=batch_size,\n",
    "            nb_epoch=nb_epoch,\n",
    "            verbose=1,\n",
    "            validation_data=(X_test, Y_test))\n",
    "\n",
    "loss, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test acc:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
