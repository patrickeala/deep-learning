{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0309 06:53:59.563328 139792627406656 deprecation.py:506] From /home/deepboy/.virtualenvs/keras_tf/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "/home/deepboy/.virtualenvs/keras_tf/lib/python3.6/site-packages/ipykernel_launcher.py:61: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2048)              2099200   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                20490     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 9,462,794\n",
      "Trainable params: 9,462,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 2.1469 - acc: 0.2030 - val_loss: 1.9428 - val_acc: 0.3096\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.9477 - acc: 0.2946 - val_loss: 1.8363 - val_acc: 0.3522\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.8675 - acc: 0.3293 - val_loss: 1.7733 - val_acc: 0.3758\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.8129 - acc: 0.3514 - val_loss: 1.7231 - val_acc: 0.3911\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7720 - acc: 0.3681 - val_loss: 1.6804 - val_acc: 0.4065\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.7370 - acc: 0.3798 - val_loss: 1.6418 - val_acc: 0.4183\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7069 - acc: 0.3886 - val_loss: 1.6162 - val_acc: 0.4230\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.6814 - acc: 0.4037 - val_loss: 1.5945 - val_acc: 0.4359\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.6589 - acc: 0.4114 - val_loss: 1.5714 - val_acc: 0.4495\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.6376 - acc: 0.4170 - val_loss: 1.5540 - val_acc: 0.4498\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.6180 - acc: 0.4258 - val_loss: 1.5373 - val_acc: 0.4565\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.6023 - acc: 0.4342 - val_loss: 1.5260 - val_acc: 0.4575\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.5877 - acc: 0.4364 - val_loss: 1.5047 - val_acc: 0.4678\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.5714 - acc: 0.4420 - val_loss: 1.5147 - val_acc: 0.4594\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.5539 - acc: 0.4499 - val_loss: 1.4852 - val_acc: 0.4739\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.5414 - acc: 0.4529 - val_loss: 1.4702 - val_acc: 0.4725\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.5301 - acc: 0.4594 - val_loss: 1.4673 - val_acc: 0.4756\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.5182 - acc: 0.4624 - val_loss: 1.4597 - val_acc: 0.4777\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.5061 - acc: 0.4650 - val_loss: 1.4425 - val_acc: 0.4850\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4950 - acc: 0.4705 - val_loss: 1.4354 - val_acc: 0.4943\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4837 - acc: 0.4728 - val_loss: 1.4343 - val_acc: 0.4883\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4741 - acc: 0.4754 - val_loss: 1.4221 - val_acc: 0.4917\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4602 - acc: 0.4843 - val_loss: 1.4261 - val_acc: 0.4856\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4547 - acc: 0.4857 - val_loss: 1.4028 - val_acc: 0.4985\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4427 - acc: 0.4901 - val_loss: 1.4057 - val_acc: 0.4976\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4322 - acc: 0.4917 - val_loss: 1.3905 - val_acc: 0.5048\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4276 - acc: 0.4942 - val_loss: 1.3867 - val_acc: 0.5059\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4199 - acc: 0.4976 - val_loss: 1.3903 - val_acc: 0.5043\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4090 - acc: 0.4994 - val_loss: 1.3728 - val_acc: 0.5083\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.3993 - acc: 0.5029 - val_loss: 1.3727 - val_acc: 0.5101\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.3903 - acc: 0.5083 - val_loss: 1.3852 - val_acc: 0.4986\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.3893 - acc: 0.5058 - val_loss: 1.3564 - val_acc: 0.5163\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.3774 - acc: 0.5126 - val_loss: 1.3591 - val_acc: 0.5147\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.3656 - acc: 0.5138 - val_loss: 1.3608 - val_acc: 0.5113\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.3618 - acc: 0.5191 - val_loss: 1.3550 - val_acc: 0.5154\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.3552 - acc: 0.5180 - val_loss: 1.3486 - val_acc: 0.5154\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.3469 - acc: 0.5234 - val_loss: 1.3346 - val_acc: 0.5247\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.3382 - acc: 0.5239 - val_loss: 1.3436 - val_acc: 0.5243\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.3311 - acc: 0.5274 - val_loss: 1.3389 - val_acc: 0.5204\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.3250 - acc: 0.5292 - val_loss: 1.3354 - val_acc: 0.5237\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.3240 - acc: 0.5315 - val_loss: 1.3240 - val_acc: 0.5253\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.3117 - acc: 0.5329 - val_loss: 1.3239 - val_acc: 0.5281\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.3045 - acc: 0.5362 - val_loss: 1.3287 - val_acc: 0.5263\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.3005 - acc: 0.5381 - val_loss: 1.3167 - val_acc: 0.5313\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.2917 - acc: 0.5410 - val_loss: 1.3144 - val_acc: 0.5337\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.2877 - acc: 0.5447 - val_loss: 1.3083 - val_acc: 0.5372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.2822 - acc: 0.5457 - val_loss: 1.3116 - val_acc: 0.5332\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.2700 - acc: 0.5469 - val_loss: 1.3037 - val_acc: 0.5347\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.2702 - acc: 0.5476 - val_loss: 1.3071 - val_acc: 0.5339\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.2605 - acc: 0.5527 - val_loss: 1.2963 - val_acc: 0.5413\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.2528 - acc: 0.5543 - val_loss: 1.3085 - val_acc: 0.5352\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.2463 - acc: 0.5557 - val_loss: 1.2989 - val_acc: 0.5337\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.2445 - acc: 0.5558 - val_loss: 1.2986 - val_acc: 0.5376\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.2370 - acc: 0.5587 - val_loss: 1.2935 - val_acc: 0.5376\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.2337 - acc: 0.5640 - val_loss: 1.2971 - val_acc: 0.5362\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.2239 - acc: 0.5643 - val_loss: 1.2881 - val_acc: 0.5458\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.2208 - acc: 0.5664 - val_loss: 1.2829 - val_acc: 0.5399\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.2097 - acc: 0.5691 - val_loss: 1.2908 - val_acc: 0.5433\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.2056 - acc: 0.5687 - val_loss: 1.2874 - val_acc: 0.5389\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.2038 - acc: 0.5708 - val_loss: 1.2882 - val_acc: 0.5428\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.1989 - acc: 0.5729 - val_loss: 1.2779 - val_acc: 0.5471\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.1897 - acc: 0.5757 - val_loss: 1.2891 - val_acc: 0.5434\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.1894 - acc: 0.5764 - val_loss: 1.2835 - val_acc: 0.5451\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.1800 - acc: 0.5804 - val_loss: 1.2733 - val_acc: 0.5440\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.1774 - acc: 0.5806 - val_loss: 1.2789 - val_acc: 0.5496\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.1690 - acc: 0.5841 - val_loss: 1.2783 - val_acc: 0.5466\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.1656 - acc: 0.5839 - val_loss: 1.2838 - val_acc: 0.5445\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.1568 - acc: 0.5870 - val_loss: 1.2687 - val_acc: 0.5519\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.1519 - acc: 0.5873 - val_loss: 1.2691 - val_acc: 0.5520\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.1474 - acc: 0.5907 - val_loss: 1.2643 - val_acc: 0.5544\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.1404 - acc: 0.5912 - val_loss: 1.2922 - val_acc: 0.5439\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.1394 - acc: 0.5932 - val_loss: 1.2708 - val_acc: 0.5539\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.1312 - acc: 0.5951 - val_loss: 1.2684 - val_acc: 0.5537\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.1269 - acc: 0.5992 - val_loss: 1.2571 - val_acc: 0.5574\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.1209 - acc: 0.6000 - val_loss: 1.2651 - val_acc: 0.5507\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.1199 - acc: 0.5978 - val_loss: 1.2636 - val_acc: 0.5585\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.1124 - acc: 0.6031 - val_loss: 1.2871 - val_acc: 0.5487\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.1071 - acc: 0.6015 - val_loss: 1.2770 - val_acc: 0.5514\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.0981 - acc: 0.6077 - val_loss: 1.2562 - val_acc: 0.5588\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.0989 - acc: 0.6068 - val_loss: 1.2659 - val_acc: 0.5561\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.0909 - acc: 0.6128 - val_loss: 1.2544 - val_acc: 0.5533\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.0921 - acc: 0.6104 - val_loss: 1.2819 - val_acc: 0.5500\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.0834 - acc: 0.6122 - val_loss: 1.2560 - val_acc: 0.5597\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.0785 - acc: 0.6138 - val_loss: 1.2477 - val_acc: 0.5594\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.0688 - acc: 0.6169 - val_loss: 1.2659 - val_acc: 0.5553\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.0714 - acc: 0.6152 - val_loss: 1.2502 - val_acc: 0.5626\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.0620 - acc: 0.6186 - val_loss: 1.2609 - val_acc: 0.5605\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.0636 - acc: 0.6172 - val_loss: 1.2682 - val_acc: 0.5556\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.0563 - acc: 0.6208 - val_loss: 1.2602 - val_acc: 0.5559\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.0511 - acc: 0.6240 - val_loss: 1.2575 - val_acc: 0.5591\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.0490 - acc: 0.6258 - val_loss: 1.2724 - val_acc: 0.5579\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.0448 - acc: 0.6256 - val_loss: 1.2544 - val_acc: 0.5592\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.0410 - acc: 0.6261 - val_loss: 1.2493 - val_acc: 0.5614\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.0301 - acc: 0.6319 - val_loss: 1.2612 - val_acc: 0.5632\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.0291 - acc: 0.6320 - val_loss: 1.2683 - val_acc: 0.5535\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.0224 - acc: 0.6343 - val_loss: 1.2583 - val_acc: 0.5638\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.0212 - acc: 0.6361 - val_loss: 1.2696 - val_acc: 0.5569\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.0093 - acc: 0.6393 - val_loss: 1.2666 - val_acc: 0.5572\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.0130 - acc: 0.6383 - val_loss: 1.2737 - val_acc: 0.5506\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.0110 - acc: 0.6373 - val_loss: 1.2579 - val_acc: 0.5639\n",
      "Test loss: 1.257948240852356\n",
      "Test acc: 0.5639\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import cifar10\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Define Variables\n",
    "nb_epoch = 100\n",
    "batch_size = 32\n",
    "nb_classes = 10\n",
    "\n",
    "\n",
    "# Train - Test splitting of data\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
    "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "# Define variables and hyperparameters\n",
    "batch_size = 128\n",
    "hidden_units = 1024\n",
    "input_shape = (3072, )\n",
    "dropout = 0.4\n",
    "num_labels=10\n",
    "\n",
    "\n",
    "# Define MLP Layers\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_units, input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(hidden_units*2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(hidden_units*2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=sgd,\n",
    "                metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Training\n",
    "model.fit(X_train, Y_train,\n",
    "            batch_size=batch_size,\n",
    "            nb_epoch=nb_epoch,\n",
    "            verbose=1,\n",
    "            validation_data=(X_test, Y_test))\n",
    "\n",
    "loss, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test acc:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
